{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, ensure you have cloned the [course repository](https://github.com/lydiaYchen/DDL25Spring).\n",
    "\n",
    "Then, open the [interactive notebook version](https://github.com/lydiaYchen/DDL25Spring/blob/main/lab/homework-1.ipynb) of this homework from your local copy.\n",
    "\n",
    "For part A, fill in the code and answers within the notebook and save your changes.\n",
    "\n",
    "For part B, create and archive the necessary Python/shell scripts together.\n",
    "\n",
    "Finally, upload the notebook and the archive to the assignment in ILIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not otherwise specified, use the following parameter values in experiment runs:\n",
    "- `nr_clients` (N): 100\n",
    "- `lr`: 0.01\n",
    "- `client_fraction` (C): 0.1\n",
    "- `nr_local_epochs` (E): 1\n",
    "- `batch_size` (B): 100\n",
    "- `nr_rounds`: 10\n",
    "- `iid`: True\n",
    "\n",
    "For all exercises, pass `seed = 10` to calls for splitting data, server initialization, or plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tutorial_1a.hfl_complete import *\n",
    "\n",
    "n = 100\n",
    "lr = 0.01\n",
    "c = 0.1\n",
    "e = 1\n",
    "b = 100\n",
    "nr_rounds = 10\n",
    "iid = True\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A1: FedSGD with weights (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Implement a version of FedSGD that uses weights in its updates, like FedAvg, instead of the gradients from the version of the tutorials. The two FedSGD versions should have the same test accuracy after each round (with a tolerance of at most 0.02%). To show this, compare their output for the following two scenarios over *5 rounds*:\n",
    "- `lr = 0.01, client_subsets = split(100, True, ...), client_fraction = 0.5`\n",
    "- `lr = 0.1, client_subsets = split(50, False, ...), client_fraction = 0.2`\n",
    "\n",
    "*Tip:* You can use the existing FedAvg implementation to minimize the amount of code writing required.\n",
    "\n",
    "_(1 point)_ Explain in which cases (about the different parameters for decentralized learning) the two are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m----> 7\u001b[0m data_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m ETA \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\N{GREEK SMALL LETTER ETA}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "data_path = Path(__file__).parent / \"data\"\n",
    "ETA = \"\\N{GREEK SMALL LETTER ETA}\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # normalize by training set mean and standard deviation\n",
    "    # resulting data has mean=0 and std=1\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    # decrease batch size if running into memory issues when testing\n",
    "    # a bespoke generator is passed to avoid reproducibility issues\n",
    "    shuffle=False, drop_last=False, batch_size=10000, generator=torch.Generator())\n",
    "\n",
    "#\n",
    "\n",
    "# Define the model\n",
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer) -> None:\n",
    "    model.train()\n",
    "\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#\n",
    "\n",
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def split(nr_clients: int, iid: bool, seed: int) -> list[Subset]:\n",
    "    rng = npr.default_rng(seed)\n",
    "\n",
    "    if iid:\n",
    "        splits = np.array_split(rng.permutation(len(train_dataset)), nr_clients)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(np.array([target for _data, target in train_dataset]))\n",
    "        shards = np.array_split(sorted_indices, 2 * nr_clients)\n",
    "        shuffled_shard_indices = rng.permutation(len(shards))\n",
    "        splits = [\n",
    "            np.concatenate([shards[i] for i in inds], dtype=np.int64)\n",
    "            for inds in shuffled_shard_indices.reshape(-1, 2)]\n",
    "\n",
    "    return [Subset(train_dataset, split) for split in cast(list[list[int]], splits)]\n",
    "\n",
    "#\n",
    "\n",
    "from dataclasses import asdict, dataclass, field\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    algorithm: str\n",
    "    n: int  # number of clients\n",
    "    c: float  # client_fraction\n",
    "    b: int  # take -1 as inf\n",
    "    e: int  # nr_local_epochs\n",
    "    lr: float  # printed as lowercase eta\n",
    "    seed: int\n",
    "    wall_time: list[float] = field(default_factory=list)\n",
    "    message_count: list[int] = field(default_factory=list)\n",
    "    test_accuracy: list[float] = field(default_factory=list)\n",
    "\n",
    "    def as_df(self, skip_wtime=True) -> DataFrame:\n",
    "        self_dict = {\n",
    "            k.capitalize().replace(\"_\", \" \"): v\n",
    "            for k, v in asdict(self).items()}\n",
    "\n",
    "        if self_dict[\"B\"] == -1:\n",
    "            self_dict[\"B\"] = \"\\N{INFINITY}\"\n",
    "\n",
    "        df = DataFrame({\"Round\": range(1, len(self.wall_time) + 1), **self_dict})\n",
    "        df = df.rename(columns={\"Lr\": ETA})\n",
    "        if skip_wtime:\n",
    "            df = df.drop(columns=[\"Wall time\"])\n",
    "        return df\n",
    "\n",
    "#\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Client(ABC):\n",
    "    def __init__(self, client_data: Subset, batch_size: int) -> None:\n",
    "        self.model = MnistCnn().to(device)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            client_data, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        ...\n",
    "\n",
    "#\n",
    "\n",
    "class Server(ABC):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        self.clients: list[Client]\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = MnistCnn().to(device)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        ...\n",
    "\n",
    "\n",
    "    def test(self) -> float:\n",
    "        correct = 0\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        return 100. * correct / len(cast(datasets.MNIST, test_loader.dataset))\n",
    "\n",
    "#\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "        self.clients = []\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\"Centralized\", 1, 1, self.batch_size, 1, self.lr, self.seed)\n",
    "\n",
    "        for epoch in tqdm(range(nr_rounds), desc=\"Epochs\", leave=False):\n",
    "            start_time = perf_counter()\n",
    "            self.generator.manual_seed(self.seed + epoch + 1)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "            elapsed_time += perf_counter() - start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(0)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "\n",
    "#\n",
    "\n",
    "class DecentralizedServer(Server):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.nr_clients = len(client_subsets)\n",
    "        self.client_fraction = client_fraction\n",
    "        self.client_sample_counts = [len(subset) for subset in client_subsets]\n",
    "        self.nr_clients_per_round = max(1, round(client_fraction * self.nr_clients))\n",
    "        self.rng = npr.default_rng(seed)\n",
    "\n",
    "# ---\n",
    "\n",
    "class GradientClient(Client):\n",
    "    def __init__(self, client_data: Subset) -> None:\n",
    "        super().__init__(client_data, len(client_data))\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "                client_values.grad = None\n",
    "\n",
    "        # seeding is not strictly necessary here\n",
    "        self.generator.manual_seed(seed)\n",
    "        self.model.train()\n",
    "\n",
    "        # this will always have one iteratioon\n",
    "        for data, target in self.loader_train:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "        return [\n",
    "            cast(torch.Tensor, x.grad).detach().cpu().clone()\n",
    "            for x in self.model.parameters()]\n",
    "\n",
    "#\n",
    "\n",
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float,\n",
    "            client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.clients = [GradientClient(subset) for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\n",
    "            \"FedSGDGradient\", self.nr_clients, self.client_fraction, -1, 1, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_gradients: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_gradients = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_gradients.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_gradients])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_gradients: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_gradients)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_gradient_parameter = zip(averaged_chosen_gradients, self.model.parameters())\n",
    "                for client_gradient, server_parameter in zip_gradient_parameter:\n",
    "                    server_parameter.grad = client_gradient.to(device=device)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "\n",
    "#\n",
    "\n",
    "class WeightClient(Client):\n",
    "    def __init__(self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        self.generator.manual_seed(seed)\n",
    "\n",
    "        for _epoch in range(self.nr_epochs):\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        return [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "\n",
    "#\n",
    "\n",
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\n",
    "            self.name, self.nr_clients, self.client_fraction, self.batch_size,\n",
    "            self.nr_local_epochs, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_weights])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_weight_parameter = zip(averaged_chosen_weights, self.model.parameters())\n",
    "                for client_weight, server_parameter in zip_weight_parameter:\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A2: Client number & fraction (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Run the necessary experiments to fill in the following table showing the final message count and test accuracy of FedSGD and FedAvg for different total client numbers:\n",
    "\n",
    "| Algorithm | N   | C   | Message count | Test accuracy |\n",
    "| --------- | --- | --- | ------------- | ------------- |\n",
    "| FedSGD    | 10  | 0.1 |               |               |\n",
    "| FedAvg    | 10  | 0.1 |               |               |\n",
    "| FedSGD    | 50  | 0.1 |               |               |\n",
    "| FedAvg    | 50  | 0.1 |               |               |\n",
    "| FedSGD    | 100 | 0.1 |               |               |\n",
    "| FedAvg    | 100 | 0.1 |               |               |\n",
    "\n",
    "Is the relationship between the metrics and client numbers monotonous?\n",
    "\n",
    "_(2 points)_ Run the experiments to fill in the table when varying the fraction of clients used in every round:\n",
    "\n",
    "| Algorithm | N   | C    | Message count | Test accuracy |\n",
    "| --------- | --- | ---- | ------------- | ------------- |\n",
    "| FedSGD    | 100 | 0.01 |               |               |\n",
    "| FedAvg    | 100 | 0.01 |               |               |\n",
    "| FedSGD    | 100 | 0.1  |               |               |\n",
    "| FedAvg    | 100 | 0.1  |               |               |\n",
    "| FedSGD    | 100 | 0.2  |               |               |\n",
    "| FedAvg    | 100 | 0.2  |               |               |\n",
    "\n",
    "How does the observed pattern differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A3: Local epoch count & (non-)IID data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no IID -> be careful with params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Create a line plot of the accuracy after each round for the following algorithm variants:\n",
    "\n",
    "- FedSGD\n",
    "- FedAvg (E=1)\n",
    "- FedAvg (E=2)\n",
    "- FedAvg (E=4)\n",
    "\n",
    "How does FedAvg compare to FedSGD? What is the effect of increasing the work clients perform locally for each update in FedAvg?\n",
    "\n",
    "_(2 points)_ Make one line plot of FedSGD and FedAvg under an IID and non-IID split for 15 rounds (leaving all other parameter values as they previously mentioned default). How does the non-IID setting affect the accuracy achieved by the two algorithms? What is the difference in terms of the smoothness of learning?\n",
    "\n",
    "_(2 points)_ Make another plot for only non-IID splits, including the FedSGD and FedAvg configs from before, and add a version for each with a learning rate of 0.001 and client fraction of 0.5. How does the stability of the new variants compare to the old ones? Why do the changes in parameters have the observed effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B1: Microbatch Pipeline Model Parallelism (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement pipeline parallelism with microbatches, as discussed during the lab.\n",
    "\n",
    "As with the other data/model parallelism examples, you will need a Python script for the nodes and a shell script to orchestrate execution.\n",
    "\n",
    "Be aware of the possibility of deadlocks: due to how `good` operates, it is possible to deadlock by having device 1 send $B_2$ to device 2 in the forward pass, and simultaneously, device 2 send $B_1$ in the backward pass.\n",
    "Since both operations will await a corresponding receive the training will stop indefinitely.\n",
    "\n",
    "Use `isend` & `irecv`, the asynchronous (non-blocking) versions of `send` & `recv` in `torch.distributed`.\n",
    "Add comments or text explaining how you expect your implementation to work and test that it runs for the same number of steps and model architecture as in class.\n",
    "\n",
    "Note that `torch.distributed`'s implementation of `gloo` does not currently support properly asynchronous communication even when using the corresponding primitives.\n",
    "Thus, you will not see the same improvements in speed as with a backend like `nccl`.\n",
    "\n",
    "You may also take advantage of the fact that `torch` gradients naturally accumulate if zeroed out.\n",
    "Also, scaling the loss by a constant is equivalent to scaling the resulting gradients by the same constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B2: Joint Data & Model Parallelism (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a training setup that uses data and model parallelism together.\n",
    "\n",
    "Create 2 pipelines of 3 stages running sequentially, where each stage works with 3 sequential micro-batches.\n",
    "\n",
    "Once again, add comments or text explaining your implementation and test it on the setting that mimics those from the class.\n",
    "\n",
    "You can use groups from `torch.distributed` to handle operations that require interaction between a subset of more than two but less than all workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
