{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first lab tutorial presents the findings and uses part of the experimental methodology from the [original Federated Learning](https://arxiv.org/pdf/1602.05629.pdf) paper. In horizontal federated learning, all clients have access to the same complete model architecture, which they train on local data, sharing information about model updates but not their data.\n",
    "\n",
    "Before starting, make sure to follow the overall setup for the labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, we download, load, and preprocess the [MNIST dataset](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits), which we will use for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:03<00:00, 3.13MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 309kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.14MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.55MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path = \"./data\"\n",
    "ETA = \"\\N{GREEK SMALL LETTER ETA}\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # normalize by training set mean and standard deviation\n",
    "    # resulting data has mean=0 and std=1\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    # decrease batch size if running into memory issues when testing\n",
    "    # a bespoke generator is passed to avoid reproducibility issues\n",
    "    shuffle=False, drop_last=False, batch_size=10000, generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a small convolutional neural network that will serve as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can define a helper method, which, given a model, a loader for iterating through a set of data, and an optimizer for updating the model trains one epoch (i.e., learns going through all the available data once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer) -> None:\n",
    "    # TODO\n",
    "    model.train() # set model to training mode\n",
    "\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device) # move data to device\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target) # calculate loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define another utility method that splits the whole dataset into the requested number of chunks, picking samples within chunks in a (non-)IID (independent and identically distributed) fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Subset for each party\n",
    "# iid, some clients has specific class of data -> clients has 2 classes each instaed of from every classes\n",
    "def split(nr_clients: int, iid: bool, seed: int) -> list[Subset]: \n",
    "    # TODO\n",
    "    #return []\n",
    "    rng = npr.default_rng(seed)\n",
    "\n",
    "    if iid:\n",
    "        splits = np.array_split(rng.permutation(len(train_dataset)), nr_clients)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(np.array([target for _data, target in train_dataset])) #separate by classes\n",
    "        shards = np.array_split(sorted_indices, 2 * nr_clients) # each client, at most 2 labels\n",
    "        shuffled_shard_indices = rng.permutation(len(shards)) # shuffle the shards\n",
    "        splits = [\n",
    "            np.concatenate([shards[i] for i in inds], dtype=np.int64)\n",
    "            for inds in shuffled_shard_indices.reshape(-1, 2)] #iterate through the shards and concatenate them to assign to clients\n",
    "\n",
    "    return [Subset(train_dataset, split) for split in cast(list[list[int]], splits)] #return the subsets, cast to list of list of int for needed type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_split = split(100, True, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a short class for holding the results of training runs and the parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass, field\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "# auxiliare class to monitor the training\n",
    "# each rounds, subset will be trained and tested (otherwise lots of communication)\n",
    "# the results will be stored in the RunResult class\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    algorithm: str\n",
    "    n: int  # number of clients\n",
    "    c: float  # client_fraction\n",
    "    b: int  # take -1 as inf\n",
    "    e: int  # nr_local_epochs \n",
    "    lr: float  # printed as lowercase eta\n",
    "    seed: int\n",
    "    wall_time: list[float] = field(default_factory=list) #simulation of time takek\n",
    "    message_count: list[int] = field(default_factory=list)\n",
    "    test_accuracy: list[float] = field(default_factory=list)\n",
    "\n",
    "    def as_df(self, skip_wtime=True) -> DataFrame:\n",
    "        self_dict = {\n",
    "            k.capitalize().replace(\"_\", \" \"): v\n",
    "            for k, v in asdict(self).items()}\n",
    "\n",
    "        if self_dict[\"B\"] == -1:\n",
    "            self_dict[\"B\"] = \"\\N{INFINITY}\"\n",
    "\n",
    "        df = DataFrame({\"Round\": range(1, len(self.wall_time) + 1), **self_dict})\n",
    "        df = df.rename(columns={\"Lr\": ETA})\n",
    "        if skip_wtime:\n",
    "            df = df.drop(columns=[\"Wall time\"])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an abstract class as a template for all distributed learning clients, defining a method for outputting an update after training a given model on local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Client(ABC):\n",
    "    def __init__(self, client_data: Subset, batch_size: int) -> None:\n",
    "        self.model = MnistCnn().to(device)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            client_data, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]: \n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the flip side, a server needs to be able to run the (distributed) training process for a given number of rounds and test the current model it possesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(ABC):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        self.clients: list[Client]\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = MnistCnn().to(device) #local copy of model\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        ...\n",
    "\n",
    "\n",
    "    def test(self) -> float:\n",
    "        # TODO\n",
    "        # return 0.\n",
    "        correct = 0\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        return 100. * correct / len(cast(datasets.MNIST, test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the previously defined server template, we can even formulate a centralized variant, which does not involve clients, as a precursor to distributed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr) \n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "        self.clients = []\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        \n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\"Centralized\", 1, 1, self.batch_size, 1, self.lr, self.seed)\n",
    "\n",
    "        for epoch in tqdm(range(nr_rounds), desc=\"Epochs\", leave=False):\n",
    "            start_time = perf_counter()\n",
    "            self.generator.manual_seed(self.seed + epoch + 1)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "            elapsed_time += perf_counter() - start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(0) # no communication, since centralized\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "        # TODO\n",
    "        #return RunResult(\"\", 0, 0., 0, 0, 0., 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>88.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>92.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>97.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>97.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>98.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round    Algorithm  N  C     B  E    η  Seed  Message count  Test accuracy\n",
       "0      1  Centralized  1  1  1024  1  0.5    42              0          88.36\n",
       "1      2  Centralized  1  1  1024  1  0.5    42              0          92.49\n",
       "2      3  Centralized  1  1  1024  1  0.5    42              0          97.35\n",
       "3      4  Centralized  1  1  1024  1  0.5    42              0          97.66\n",
       "4      5  Centralized  1  1  1024  1  0.5    42              0          98.33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralized_server = CentralizedServer(0.5, 1024, 42)\n",
    "result_centralized = centralized_server.run(5)\n",
    "centralized_df = result_centralized.as_df()\n",
    "centralized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the template with some setup steps common to all decentralized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentralizedServer(Server):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.nr_clients = len(client_subsets)\n",
    "        self.client_fraction = client_fraction\n",
    "        self.client_sample_counts = [len(subset) for subset in client_subsets]\n",
    "        self.nr_clients_per_round = max(1, round(client_fraction * self.nr_clients))\n",
    "        self.rng = npr.default_rng(seed)\n",
    "        # TODO\n",
    "        #return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two federated learning algorithms from the paper follow, alongside an overview of metric plotting.\n",
    "\n",
    "One by passing the gradient from clients to server, less flexible\n",
    "\n",
    "Or directly passing the final weight\n",
    "\n",
    "Weight => flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the FedSGD algorithm, the baseline from the paper, we first need to define the client, and we choose to pass gradients from the client as the update result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientClient(Client):\n",
    "    def __init__(self, client_data: Subset) -> None:\n",
    "        super().__init__(client_data, len(client_data))\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # TODO\n",
    "        #return []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights): #client and server values together\n",
    "                client_values[:] = server_values\n",
    "                client_values.grad = None #set grad to 0\n",
    "\n",
    "        # seeding is not strictly necessary here\n",
    "        self.generator.manual_seed(seed)\n",
    "        self.model.train()\n",
    "\n",
    "        # this will always have one iteration (infinity batch size)\n",
    "        for data, target in self.loader_train:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward() #calculate gradients\n",
    "\n",
    "        return [\n",
    "            cast(torch.Tensor, x.grad).detach().cpu().clone() #detach and duplicate from graph because no need to calculate gradients (normally through machines)\n",
    "            for x in self.model.parameters()] #return the gradients to the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the corresponding server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float,\n",
    "            client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr) #need optimizer because gradient \n",
    "        self.clients = [GradientClient(subset) for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\n",
    "            \"FedSGDGradient\", self.nr_clients, self.client_fraction, -1, 1, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False) #find active clients\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients) #total nb of samples from clients\n",
    "            chosen_adjusted_gradients: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients: \n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round #controlled variability\n",
    "                client_gradients = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_gradients.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_gradients])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time) #simulate parallel training\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_gradients: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_gradients)] #average the gradients once all clients have updated\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_gradient_parameter = zip(averaged_chosen_gradients, self.model.parameters())\n",
    "                for client_gradient, server_parameter in zip_gradient_parameter:\n",
    "                    server_parameter.grad = client_gradient.to(device=device) #copy average gardient to our models\n",
    "\n",
    "            self.optimizer.step() #update the weights\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "        \n",
    "        # TODO\n",
    "        #return RunResult(\"\", 0, 0., 0, 0, 0., 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>120</td>\n",
       "      <td>10.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>160</td>\n",
       "      <td>12.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>15.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round       Algorithm    N    C  B  E     η  Seed  Message count  \\\n",
       "0      1  FedSGDGradient  100  0.2  ∞  1  0.02    42             40   \n",
       "1      2  FedSGDGradient  100  0.2  ∞  1  0.02    42             80   \n",
       "2      3  FedSGDGradient  100  0.2  ∞  1  0.02    42            120   \n",
       "3      4  FedSGDGradient  100  0.2  ∞  1  0.02    42            160   \n",
       "4      5  FedSGDGradient  100  0.2  ∞  1  0.02    42            200   \n",
       "\n",
       "   Test accuracy  \n",
       "0           8.89  \n",
       "1           9.47  \n",
       "2          10.31  \n",
       "3          12.56  \n",
       "4          15.72  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedsgd_gradient_server = FedSgdGradientServer(0.02, sample_split, 0.2, 42)\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FedAvg algorithm is the paper's main contribution, requiring a client that passes around weights instead of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightClient(Client):\n",
    "    def __init__(self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        self.generator.manual_seed(seed)\n",
    "\n",
    "        for _epoch in range(self.nr_epochs): #train for a number of epochs (multiples this time)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        return [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "\n",
    "        \n",
    "        # TODO\n",
    "        #return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we define the actual server code for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # TODO\n",
    "        #return RunResult(\"\", 0, 0., 0, 0, 0., 0)\n",
    "\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\n",
    "            self.name, self.nr_clients, self.client_fraction, self.batch_size,\n",
    "            self.nr_local_epochs, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients) #total nb of samples from clients, bc clients data not same amount\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_weights])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_weight_parameter = zip(averaged_chosen_weights, self.model.parameters())\n",
    "                for client_weight, server_parameter in zip_weight_parameter:\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "                    #no optimizer since we have weights\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>20.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>54.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>120</td>\n",
       "      <td>67.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>160</td>\n",
       "      <td>75.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>77.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round Algorithm    N    C    B  E     η  Seed  Message count  Test accuracy\n",
       "0      1    FedAvg  100  0.2  200  2  0.02    42             40          20.95\n",
       "1      2    FedAvg  100  0.2  200  2  0.02    42             80          54.43\n",
       "2      3    FedAvg  100  0.2  200  2  0.02    42            120          67.55\n",
       "3      4    FedAvg  100  0.2  200  2  0.02    42            160          75.07\n",
       "4      5    FedAvg  100  0.2  200  2  0.02    42            200          77.23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedavg_server = FedAvgServer(0.02, 200, sample_split, 0.2, 2, 42)\n",
    "result_fedavg = fedavg_server.run(5)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at a quick example of plotting the accuracy per round of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([fedavg_df, fedsgd_gradient_df], ignore_index=True)\n",
    "ax = sns.lineplot(df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=0)\n",
    "_ = ax.set_xticks(df[\"Round\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg-> much more efficient,\n",
    "Both should converge to the same\n",
    "\n",
    "Different models for each cases, (specific tuned from general model for uses case)\n",
    "\n",
    "For one client, different entities might have different informations -> vertical federated.\n",
    "\n",
    "Clients can also be the \"server\" instead of using federated server.\n",
    "\n",
    "One device might not have the computation power, so we distribute the maths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
