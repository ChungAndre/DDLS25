{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first lab tutorial presents the findings and uses part of the experimental methodology from the [original Federated Learning](https://arxiv.org/pdf/1602.05629.pdf) paper. In horizontal federated learning, all clients have access to the same complete model architecture, which they train on local data, sharing information about model updates but not their data.\n",
    "\n",
    "Before starting, make sure to follow the overall setup for the labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, we download, load, and preprocess the [MNIST dataset](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits), which we will use for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path = \"./data\"\n",
    "ETA = \"\\N{GREEK SMALL LETTER ETA}\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # normalize by training set mean and standard deviation\n",
    "    # resulting data has mean=0 and std=1\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    # decrease batch size if running into memory issues when testing\n",
    "    # a bespoke generator is passed to avoid reproducibility issues\n",
    "    shuffle=False, drop_last=False, batch_size=10000, generator=torch.Generator())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a small convolutional neural network that will serve as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can define a helper method, which, given a model, a loader for iterating through a set of data, and an optimizer for updating the model trains one epoch (i.e., learns going through all the available data once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer) -> None:\n",
    "    # TODO\n",
    "    model.train() # set model to training mode\n",
    "\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device) # move data to device\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target) # calculate loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define another utility method that splits the whole dataset into the requested number of chunks, picking samples within chunks in a (non-)IID (independent and identically distributed) fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Subset for each party\n",
    "# iid, some clients has specific class of data -> clients has 2 classes each instaed of from every classes\n",
    "def split(nr_clients: int, iid: bool, seed: int) -> list[Subset]: \n",
    "    # TODO\n",
    "    #return []\n",
    "    rng = npr.default_rng(seed)\n",
    "\n",
    "    if iid:\n",
    "        splits = np.array_split(rng.permutation(len(train_dataset)), nr_clients)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(np.array([target for _data, target in train_dataset])) #separate by classes\n",
    "        shards = np.array_split(sorted_indices, 2 * nr_clients) # each client, at most 2 labels\n",
    "        shuffled_shard_indices = rng.permutation(len(shards)) # shuffle the shards\n",
    "        splits = [\n",
    "            np.concatenate([shards[i] for i in inds], dtype=np.int64)\n",
    "            for inds in shuffled_shard_indices.reshape(-1, 2)] #iterate through the shards and concatenate them to assign to clients\n",
    "\n",
    "    return [Subset(train_dataset, split) for split in cast(list[list[int]], splits)] #return the subsets, cast to list of list of int for needed type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_split = split(100, True, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a short class for holding the results of training runs and the parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass, field\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "# auxiliare class to monitor the training\n",
    "# each rounds, subset will be trained and tested (otherwise lots of communication)\n",
    "# the results will be stored in the RunResult class\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    algorithm: str\n",
    "    n: int  # number of clients\n",
    "    c: float  # client_fraction\n",
    "    b: int  # take -1 as inf\n",
    "    e: int  # nr_local_epochs \n",
    "    lr: float  # printed as lowercase eta\n",
    "    seed: int\n",
    "    wall_time: list[float] = field(default_factory=list) #simulation of time takek\n",
    "    message_count: list[int] = field(default_factory=list)\n",
    "    test_accuracy: list[float] = field(default_factory=list)\n",
    "\n",
    "    def as_df(self, skip_wtime=True) -> DataFrame:\n",
    "        self_dict = {\n",
    "            k.capitalize().replace(\"_\", \" \"): v\n",
    "            for k, v in asdict(self).items()}\n",
    "\n",
    "        if self_dict[\"B\"] == -1:\n",
    "            self_dict[\"B\"] = \"\\N{INFINITY}\"\n",
    "\n",
    "        df = DataFrame({\"Round\": range(1, len(self.wall_time) + 1), **self_dict})\n",
    "        df = df.rename(columns={\"Lr\": ETA})\n",
    "        if skip_wtime:\n",
    "            df = df.drop(columns=[\"Wall time\"])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an abstract class as a template for all distributed learning clients, defining a method for outputting an update after training a given model on local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Client(ABC):\n",
    "    def __init__(self, client_data: Subset, batch_size: int) -> None:\n",
    "        self.model = MnistCnn().to(device)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            client_data, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]: \n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the flip side, a server needs to be able to run the (distributed) training process for a given number of rounds and test the current model it possesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(ABC):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        self.clients: list[Client]\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = MnistCnn().to(device) #local copy of model\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        ...\n",
    "\n",
    "\n",
    "    def test(self) -> float:\n",
    "        # TODO\n",
    "        # return 0.\n",
    "        correct = 0\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        return 100. * correct / len(cast(datasets.MNIST, test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the previously defined server template, we can even formulate a centralized variant, which does not involve clients, as a precursor to distributed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr) \n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "        self.clients = []\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        \n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\"Centralized\", 1, 1, self.batch_size, 1, self.lr, self.seed)\n",
    "\n",
    "        for epoch in tqdm(range(nr_rounds), desc=\"Epochs\", leave=False):\n",
    "            start_time = perf_counter()\n",
    "            self.generator.manual_seed(self.seed + epoch + 1)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "            elapsed_time += perf_counter() - start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(0) # no communication, since centralized\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "        # TODO\n",
    "        #return RunResult(\"\", 0, 0., 0, 0, 0., 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>90.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>96.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>97.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>98.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>98.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round    Algorithm  N  C     B  E    η  Seed  Message count  Test accuracy\n",
       "0      1  Centralized  1  1  1024  1  0.5    42              0          90.12\n",
       "1      2  Centralized  1  1  1024  1  0.5    42              0          96.48\n",
       "2      3  Centralized  1  1  1024  1  0.5    42              0          97.53\n",
       "3      4  Centralized  1  1  1024  1  0.5    42              0          98.04\n",
       "4      5  Centralized  1  1  1024  1  0.5    42              0          98.22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralized_server = CentralizedServer(0.5, 1024, 42)\n",
    "result_centralized = centralized_server.run(5)\n",
    "centralized_df = result_centralized.as_df()\n",
    "centralized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the template with some setup steps common to all decentralized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentralizedServer(Server):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.nr_clients = len(client_subsets)\n",
    "        self.client_fraction = client_fraction\n",
    "        self.client_sample_counts = [len(subset) for subset in client_subsets]\n",
    "        self.nr_clients_per_round = max(1, round(client_fraction * self.nr_clients))\n",
    "        self.rng = npr.default_rng(seed)\n",
    "        # TODO\n",
    "        #return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two federated learning algorithms from the paper follow, alongside an overview of metric plotting.\n",
    "\n",
    "One by passing the gradient from clients to server, less flexible\n",
    "\n",
    "Or directly passing the final weight\n",
    "\n",
    "Weight => flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the FedSGD algorithm, the baseline from the paper, we first need to define the client, and we choose to pass gradients from the client as the update result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientClient(Client):\n",
    "    def __init__(self, client_data: Subset) -> None:\n",
    "        super().__init__(client_data, len(client_data))\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # TODO\n",
    "        #return []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights): #client and server values together\n",
    "                client_values[:] = server_values\n",
    "                client_values.grad = None #set grad to 0\n",
    "\n",
    "        # seeding is not strictly necessary here\n",
    "        self.generator.manual_seed(seed)\n",
    "        self.model.train()\n",
    "\n",
    "        # this will always have one iteration (infinity batch size)\n",
    "        for data, target in self.loader_train:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward() #calculate gradients\n",
    "\n",
    "        return [\n",
    "            cast(torch.Tensor, x.grad).detach().cpu().clone() #detach and duplicate from graph because no need to calculate gradients (normally through machines)\n",
    "            for x in self.model.parameters()] #return the gradients to the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the corresponding server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float,\n",
    "            client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr) #need optimizer because gradient \n",
    "        self.clients = [GradientClient(subset) for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\n",
    "            \"FedSGDGradient\", self.nr_clients, self.client_fraction, -1, 1, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False) #find active clients\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients) #total nb of samples from clients\n",
    "            chosen_adjusted_gradients: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients: \n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round #controlled variability\n",
    "                client_gradients = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_gradients.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_gradients])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time) #simulate parallel training\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_gradients: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_gradients)] #average the gradients once all clients have updated\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_gradient_parameter = zip(averaged_chosen_gradients, self.model.parameters())\n",
    "                for client_gradient, server_parameter in zip_gradient_parameter:\n",
    "                    server_parameter.grad = client_gradient.to(device=device) #copy average gardient to our models\n",
    "\n",
    "            self.optimizer.step() #update the weights\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "        \n",
    "        # TODO\n",
    "        #return RunResult(\"\", 0, 0., 0, 0, 0., 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>120</td>\n",
       "      <td>10.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>160</td>\n",
       "      <td>12.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>15.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round       Algorithm    N    C  B  E     η  Seed  Message count  \\\n",
       "0      1  FedSGDGradient  100  0.2  ∞  1  0.02    42             40   \n",
       "1      2  FedSGDGradient  100  0.2  ∞  1  0.02    42             80   \n",
       "2      3  FedSGDGradient  100  0.2  ∞  1  0.02    42            120   \n",
       "3      4  FedSGDGradient  100  0.2  ∞  1  0.02    42            160   \n",
       "4      5  FedSGDGradient  100  0.2  ∞  1  0.02    42            200   \n",
       "\n",
       "   Test accuracy  \n",
       "0           8.89  \n",
       "1           9.47  \n",
       "2          10.31  \n",
       "3          12.56  \n",
       "4          15.72  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedsgd_gradient_server = FedSgdGradientServer(0.02, sample_split, 0.2, 42)\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FedAvg algorithm is the paper's main contribution, requiring a client that passes around weights instead of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightClient(Client):\n",
    "    def __init__(self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        self.generator.manual_seed(seed)\n",
    "\n",
    "        for _epoch in range(self.nr_epochs): #train for a number of epochs (multiples this time)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        return [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "\n",
    "        \n",
    "        # TODO\n",
    "        #return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we define the actual server code for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # TODO\n",
    "        #return RunResult(\"\", 0, 0., 0, 0, 0., 0)\n",
    "\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\n",
    "            self.name, self.nr_clients, self.client_fraction, self.batch_size,\n",
    "            self.nr_local_epochs, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients) #total nb of samples from clients, bc clients data not same amount\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_weights])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_weight_parameter = zip(averaged_chosen_weights, self.model.parameters())\n",
    "                for client_weight, server_parameter in zip_weight_parameter:\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "                    #no optimizer since we have weights\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>20.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>54.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>120</td>\n",
       "      <td>67.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>160</td>\n",
       "      <td>75.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>77.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round Algorithm    N    C    B  E     η  Seed  Message count  Test accuracy\n",
       "0      1    FedAvg  100  0.2  200  2  0.02    42             40          20.95\n",
       "1      2    FedAvg  100  0.2  200  2  0.02    42             80          54.43\n",
       "2      3    FedAvg  100  0.2  200  2  0.02    42            120          67.56\n",
       "3      4    FedAvg  100  0.2  200  2  0.02    42            160          75.07\n",
       "4      5    FedAvg  100  0.2  200  2  0.02    42            200          77.23"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedavg_server = FedAvgServer(0.02, 200, sample_split, 0.2, 2, 42)\n",
    "result_fedavg = fedavg_server.run(5)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at a quick example of plotting the accuracy per round of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([fedavg_df, fedsgd_gradient_df], ignore_index=True)\n",
    "ax = sns.lineplot(df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=0)\n",
    "_ = ax.set_xticks(df[\"Round\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg-> much more efficient,\n",
    "Both should converge to the same\n",
    "\n",
    "Different models for each cases, (specific tuned from general model for uses case)\n",
    "\n",
    "For one client, different entities might have different informations -> vertical federated.\n",
    "\n",
    "Clients can also be the \"server\" instead of using federated server.\n",
    "\n",
    "One device might not have the computation power, so we distribute the maths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
